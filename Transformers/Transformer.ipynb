{
 "cells": [
  {
   "attachments": {
    "47d4570b-652a-4c1c-a72e-af0cb5fd7967.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "14dc8464-bc89-4d36-965e-6c73f8acf072",
   "metadata": {},
   "source": [
    "# Step-by-Step Implementation of Positional Encoding\n",
    "### Step 1: Understand the Formula\n",
    " ![image.png](attachment:47d4570b-652a-4c1c-a72e-af0cb5fd7967.png)\n",
    "# Step 2: Define a Positional Encoding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef7bf3e4-388b-482c-a854-4f94a8908dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, max_len, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.max_len = max_len\n",
    "        self.d_model = d_model\n",
    "        self.positional_encoding = self.compute_positional_encoding()\n",
    "\n",
    "    def compute_positional_encoding(self):\n",
    "        positions = np.arange(self.max_len)[:, np.newaxis]  # Shape: (max_len, 1)\n",
    "        div_term = np.exp(np.arange(0, self.d_model, 2) * (-np.log(10000.0) / self.d_model))  # Shape: (d_model/2,)\n",
    "        \n",
    "        pe = np.zeros((self.max_len, self.d_model))  # Shape: (max_len, d_model)\n",
    "        pe[:, 0::2] = np.sin(positions * div_term)  # Apply sine to even indices\n",
    "        pe[:, 1::2] = np.cos(positions * div_term)  # Apply cosine to odd indices\n",
    "\n",
    "        return tf.convert_to_tensor(pe, dtype=tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        batch_size, seq_len, d_model = tf.shape(inputs)[0], tf.shape(inputs)[1], tf.shape(inputs)[2]\n",
    "        return inputs + self.positional_encoding[:seq_len, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95c4051-a604-4a7a-8d9d-324850ed741c",
   "metadata": {},
   "source": [
    "# Step 1: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a82bd404-2317-4633-9cbd-c8cd43c46cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Source: tf.Tensor(\n",
      "[[8 7 9 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [6 4 3 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]], shape=(2, 64), dtype=int64)\n",
      "Tokenized Target: tf.Tensor(\n",
      "[[2 4 7 8 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [6 3 9 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]], shape=(2, 64), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "# Define tokenization parameters\n",
    "vocab_size = 20000  # Maximum vocabulary size\n",
    "sequence_length = 64  # Max length of each input sentence\n",
    "\n",
    "# Tokenizer for source language (English)\n",
    "source_vectorizer = TextVectorization(max_tokens=vocab_size, output_mode='int', output_sequence_length=sequence_length)\n",
    "\n",
    "# Tokenizer for target language (Telugu)\n",
    "target_vectorizer = TextVectorization(max_tokens=vocab_size, output_mode='int', output_sequence_length=sequence_length)\n",
    "\n",
    "# Sample text data\n",
    "source_texts = [\"Hello, how are you?\", \"I love machine learning.\"]\n",
    "target_texts = [\"‡∞π‡∞≤‡±ã, ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞é‡∞≤‡∞æ ‡∞â‡∞®‡±ç‡∞®‡∞æ‡∞∞‡±Å?\", \"‡∞®‡±á‡∞®‡±Å ‡∞Ø‡∞Ç‡∞§‡±ç‡∞∞ ‡∞Ö‡∞≠‡±ç‡∞Ø‡∞æ‡∞∏‡∞æ‡∞®‡±ç‡∞®‡∞ø ‡∞™‡±ç‡∞∞‡±á‡∞Æ‡∞ø‡∞∏‡±ç‡∞§‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞®‡±Å.\"]\n",
    "\n",
    "# Adapt tokenizers to the dataset\n",
    "source_vectorizer.adapt(source_texts)\n",
    "target_vectorizer.adapt(target_texts)\n",
    "\n",
    "# Example tokenization\n",
    "print(\"Tokenized Source:\", source_vectorizer(source_texts))\n",
    "print(\"Tokenized Target:\", target_vectorizer(target_texts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c5c40d-4ed7-4de5-a86b-ce0371b08350",
   "metadata": {},
   "source": [
    "# Step 2: Embedding Layer\n",
    "### Why We Use an Embedding Layer:\n",
    "* Converts discrete token IDs into dense, meaningful vectors.\n",
    "* mask_zero=True ensures the Transformer ignores padding tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c72caf49-e36b-4604-8fac-3986d88ccf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedded Source Shape: (2, 64, 128)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding_dim = 128  # Dimension of word embeddings\n",
    "\n",
    "# Define embedding layers\n",
    "source_embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim, mask_zero=True)\n",
    "target_embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim, mask_zero=True)\n",
    "\n",
    "# Example usage\n",
    "source_tokens = source_vectorizer(source_texts)  # Convert text to tokens\n",
    "embedded_source = source_embedding(source_tokens)  # Convert tokens to dense vectors\n",
    "\n",
    "print(\"Embedded Source Shape:\", embedded_source.shape)  # (batch_size, sequence_length, embedding_dim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a277bde4-6aae-43c4-b966-e8993f841c58",
   "metadata": {},
   "source": [
    "# Step 3: Positional Encoding\n",
    "* Transformers don‚Äôt have recurrence (like RNNs), so we need positional encoding to indicate word order.\n",
    "* ‚úÖ What This Does:\n",
    "* Adds sinusoidal positional information to embeddings.\n",
    "* Ensures word order is captured by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "617e551b-c7ae-47bf-9e35-bb41ee8a0d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class PositionalEncoding(tf.keras.layers.Layer):\n",
    "    def __init__(self, max_len, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.max_len = max_len\n",
    "\n",
    "        # Compute positional encoding\n",
    "        positions = np.arange(max_len)[:, np.newaxis]  # (max_len, 1)\n",
    "        div_term = np.exp(np.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))  # (d_model/2,)\n",
    "\n",
    "        pe = np.zeros((max_len, d_model))\n",
    "        pe[:, 0::2] = np.sin(positions * div_term)  # Apply sine to even indices\n",
    "        pe[:, 1::2] = np.cos(positions * div_term)  # Apply cosine to odd indices\n",
    "\n",
    "        self.positional_encoding = tf.constant(pe, dtype=tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        seq_len = tf.shape(inputs)[1]\n",
    "        return inputs + self.positional_encoding[:seq_len, :]\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return mask  # Preserve the mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "074c7702-8bbc-47e6-9d4e-0dcb93a0549f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after Positional Encoding: (2, 64, 128)\n"
     ]
    }
   ],
   "source": [
    "# Apply positional encoding to embeddings\n",
    "pos_encoding = PositionalEncoding(sequence_length, embedding_dim)\n",
    "\n",
    "# Example usage\n",
    "embedded_source_with_pe = pos_encoding(embedded_source)\n",
    "\n",
    "print(\"Shape after Positional Encoding:\", embedded_source_with_pe.shape)  # (batch_size, sequence_length, embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8aeaf2-8677-430a-b767-a985eb003c7f",
   "metadata": {},
   "source": [
    "# Step 4: Transformer Encoder\n",
    "* Now that we have tokenized input, embeddings, and positional encoding, let‚Äôs build the Transformer Encoder.\n",
    "* ‚úÖ What This Does:\n",
    "* Applies multi-head self-attention to the input.\n",
    "* Passes the result through a feed-forward network.\n",
    "* Uses Layer Normalization & Residual Connections to stabilize training."
   ]
  },
  {
   "cell_type": "raw",
   "id": "8050c1f7-9677-44c8-8f7f-9ed0b507fad3",
   "metadata": {},
   "source": [
    "from tensorflow.keras.layers import LayerNormalization, MultiHeadAttention, Dense, Dropout\n",
    "\n",
    "class TransformerEncoder(Layer):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, dropout_rate=0.1):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.mha = MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            Dense(ff_dim, activation=\"relu\"),\n",
    "            Dense(d_model)\n",
    "        ])\n",
    "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = Dropout(dropout_rate)\n",
    "        self.dropout2 = Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, inputs, mask=None, training=True):\n",
    "        # Multi-Head Self-Attention\n",
    "        attn_output = self.mha(inputs, inputs, inputs, attention_mask=mask)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)  # Residual Connection\n",
    "\n",
    "        # Feed Forward Network\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # Residual Connection\n",
    "\n",
    "        return out2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4831a95b-d8ac-4bb8-ba01-392b8321e40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        # Multi-head Self-Attention\n",
    "        self.mha = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "\n",
    "        # Feed-Forward Network (Dense layers)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(dff, activation='relu'),  # Expand dimension\n",
    "            tf.keras.layers.Dense(d_model)  # Reduce back to d_model\n",
    "        ])\n",
    "\n",
    "        # Layer Normalization\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        # Dropout layers\n",
    "        self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, training, mask):\n",
    "        # 1Ô∏è‚É£ Self-Attention Layer (with residual connection)\n",
    "        attn_output = self.mha(x, x, x, attention_mask=mask)  # (batch_size, seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output)  # Add & Normalize\n",
    "\n",
    "        # 2Ô∏è‚É£ Feed-Forward Network (with residual connection)\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # Add & Normalize\n",
    "\n",
    "        return out2  # (batch_size, seq_len, d_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f68125-1aa1-45e5-9e01-ff7a9fdd7b0e",
   "metadata": {},
   "source": [
    "# Recap of What We Have Done So Far üöÄ\n",
    "* 1Ô∏è‚É£ Tokenization: Convert text into numbers using TextVectorization.\n",
    "* 2Ô∏è‚É£ Embedding Layer: Map tokens to dense vectors (Embedding).\n",
    "* 3Ô∏è‚É£ Positional Encoding: Add position information (PositionalEncoding).\n",
    "* 4Ô∏è‚É£ Transformer Encoder: Build a single encoder block (Multi-Head Attention + Feed Forward).\n",
    "\n",
    "* Now that we have the Encoder, the next step is stacking multiple Encoder layers before moving to the Decoder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce678763-b025-407a-b3ad-34c31f9d7d3a",
   "metadata": {},
   "source": [
    "# 1Ô∏è‚É£ What Does Stacking Encoders Mean?\n",
    "* A Transformer encoder consists of multiple identical encoder layers stacked on top of each other.\n",
    "* Each layer processes the input and passes the output to the next encoder in the stack.\n",
    "\n",
    "* üìù Key Idea:\n",
    "* Each encoder layer learns progressively more abstract features about the input sentence.\n",
    "\n",
    "* üìå Example:\n",
    "\n",
    "* Lower layers capture word-level dependencies.\n",
    "* Higher layers capture sentence-level meaning.\n",
    "* 2Ô∏è‚É£ Code: Stacking Encoders in TensorFlow/Keras\n",
    "* Now, let's build the full encoder stack using multiple layers.\n",
    "# 3Ô∏è‚É£ How Does It Work?\n",
    "* Token Embedding: Converts input tokens into dense vectors.\n",
    "* Positional Encoding: Adds positional information to the embeddings.\n",
    "* Dropout: Prevents overfitting.\n",
    "* Stacked Encoder Layers: Each encoder layer refines the representation by passing data through multi-head attention and feed-forward networks.\n",
    "* üìå Each layer gets the same input shape, processes it, and passes it forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9e54670-cf08-4f3e-9f1f-52214b4b688b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class TransformerEncoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, max_len, dropout_rate=0.1):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Token Embedding + Positional Encoding\n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model, mask_zero=True)\n",
    "        self.pos_encoding = PositionalEncoding(max_len, d_model)\n",
    "\n",
    "        # Stack multiple encoder layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, training=True, mask=None):  # ‚úÖ Default keyword arguments\n",
    "        seq_len = tf.shape(x)[1]\n",
    "    \n",
    "        # 1. Token Embedding\n",
    "        x = self.embedding(x)  # Shape: (batch_size, seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))  # Scale embeddings\n",
    "    \n",
    "        # 2. Add Positional Encoding\n",
    "        x = self.pos_encoding(x)\n",
    "    \n",
    "        # 3. Apply Dropout\n",
    "        x = self.dropout(x, training=training)\n",
    "    \n",
    "        # 4. Pass through multiple encoder layers (fix here)\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training=training, mask=mask)  # ‚úÖ Fix\n",
    "    \n",
    "        return x  # Final encoder representation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "973245b0-a393-4b35-847f-b5fe681dc061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder Output Shape: (2, 50, 512)\n"
     ]
    }
   ],
   "source": [
    "num_layers = 6      # Number of encoder layers\n",
    "d_model = 512       # Embedding dimension\n",
    "num_heads = 8       # Multi-head attention heads\n",
    "dff = 2048          # Feed-forward network size\n",
    "vocab_size = 10000  # Vocabulary size\n",
    "max_len = 100       # Maximum input length\n",
    "\n",
    "encoder = TransformerEncoder(num_layers, d_model, num_heads, dff, vocab_size, max_len)\n",
    "\n",
    "# Dummy input\n",
    "sample_input = tf.random.uniform((2, 50), dtype=tf.int32, minval=0, maxval=200)  # (batch_size=2, seq_len=50)\n",
    "mask = None  # Padding mask (to be defined properly)\n",
    "\n",
    "output = encoder(sample_input, training=True, mask=mask)\n",
    "print(\"Encoder Output Shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d582f8d9-38b3-4e55-9442-b47f4663cbb6",
   "metadata": {},
   "source": [
    "# Step 1: Implement a Single Decoder Layer\n",
    "* Each decoder layer consists of:\n",
    "\n",
    "* Masked Multi-Head Self-Attention (prevents looking ahead in sequences)\n",
    "* Encoder-Decoder Attention (allows the decoder to focus on encoder outputs)\n",
    "* Feed-Forward Network\n",
    "* Residual connections & Layer Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbe35423-0111-46f8-94b4-55c018edb152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, dropout_rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        # 1Ô∏è‚É£ Self-Attention (with causal masking)\n",
    "        self.mha1 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "\n",
    "        # 2Ô∏è‚É£ Encoder-Decoder Cross Attention\n",
    "        self.mha2 = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=d_model)\n",
    "\n",
    "        # 3Ô∏è‚É£ Feed-Forward Network\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(dff, activation='relu'),  # Expand dimension\n",
    "            tf.keras.layers.Dense(d_model)  # Reduce back to d_model\n",
    "        ])\n",
    "\n",
    "        # Layer Normalization\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        # Dropout layers\n",
    "        self.dropout1 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, enc_output, training, padding_mask):\n",
    "        # 1Ô∏è‚É£ Self-Attention with **causal masking applied automatically**\n",
    "        attn1 = self.mha1(x, x, x, use_causal_mask=True, training=training)\n",
    "        attn1 = self.dropout1(attn1, training=training)\n",
    "        out1 = self.layernorm1(x + attn1)  # Add & Normalize\n",
    "\n",
    "        # 2Ô∏è‚É£ Encoder-Decoder Cross Attention (with padding mask)\n",
    "        attn2 = self.mha2(out1, enc_output, enc_output, attention_mask=padding_mask, training=training)\n",
    "        attn2 = self.dropout2(attn2, training=training)\n",
    "        out2 = self.layernorm2(out1 + attn2)  # Add & Normalize\n",
    "\n",
    "        # 3Ô∏è‚É£ Feed-Forward Network\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output, training=training)\n",
    "        out3 = self.layernorm3(out2 + ffn_output)  # Add & Normalize\n",
    "\n",
    "        return out3  # (batch_size, target_seq_len, d_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab28f13-a6c2-4f3e-8e61-69cc0cd2c773",
   "metadata": {},
   "source": [
    "# Step 2: Implement the Full Transformer Decoder\n",
    "* The TransformerDecoder stacks multiple DecoderLayer layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2635adf-1b1f-4049-8d25-94b0b6a0171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class TransformerDecoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, max_len, dropout_rate=0.1):\n",
    "        super(TransformerDecoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Token Embedding + Positional Encoding\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model, mask_zero=True)\n",
    "        self.pos_encoding = PositionalEncoding(max_len, d_model)\n",
    "\n",
    "        # Stack multiple decoder layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, dropout_rate) for _ in range(num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "\n",
    "    def call(self, x, enc_output, training=True, padding_mask=None):  # ‚úÖ Ensure training is keyword argument\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # 1Ô∏è‚É£ Token Embedding\n",
    "        x = self.embedding(x)  # Shape: (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))  # Scale embeddings\n",
    "\n",
    "        # 2Ô∏è‚É£ Add Positional Encoding\n",
    "        x = self.pos_encoding(x)\n",
    "\n",
    "        # 3Ô∏è‚É£ Apply Dropout\n",
    "        x = self.dropout(x, training=training)\n",
    "\n",
    "        # 4Ô∏è‚É£ Pass through multiple decoder layers\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.dec_layers[i](x, enc_output, training=training, padding_mask=padding_mask)  # ‚úÖ Fix\n",
    "\n",
    "        return x  # (batch_size, target_seq_len, d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68e3a5b5-0519-48de-85b6-cd8d1fcdad6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder Output Shape: (2, 50, 512)\n"
     ]
    }
   ],
   "source": [
    "num_layers = 6        # Number of decoder layers\n",
    "d_model = 512         # Embedding dimension\n",
    "num_heads = 8         # Multi-head attention heads\n",
    "dff = 2048            # Feed-forward network size\n",
    "target_vocab_size = 10000  # Vocabulary size\n",
    "max_len = 100         # Maximum target sequence length\n",
    "\n",
    "decoder = TransformerDecoder(num_layers, d_model, num_heads, dff, target_vocab_size, max_len)\n",
    "\n",
    "# Dummy inputs\n",
    "target_input = tf.random.uniform((2, 50), dtype=tf.int32, minval=0, maxval=200)  # (batch_size=2, seq_len=50)\n",
    "encoder_output = tf.random.uniform((2, 50, d_model))  # Encoder output\n",
    "padding_mask = None  # (Normally, this would be generated based on padding tokens)\n",
    "\n",
    "decoder_output = decoder(target_input, encoder_output, training=True, padding_mask=padding_mask)\n",
    "print(\"Decoder Output Shape:\", decoder_output.shape)  # Expected: (batch_size, target_seq_len, d_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68ec6e1-fa40-4744-8b77-3882a4763207",
   "metadata": {},
   "source": [
    "# Full Transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f89358ed-8af9-41d1-af9d-1750b468c123",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff,\n",
    "                 input_vocab_size, target_vocab_size, max_len, dropout_rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = TransformerEncoder(num_layers, d_model, num_heads, dff,\n",
    "                                          input_vocab_size, max_len, dropout_rate)\n",
    "        self.decoder = TransformerDecoder(num_layers, d_model, num_heads, dff,\n",
    "                                          target_vocab_size, max_len, dropout_rate)\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "\n",
    "    def call(self, inputs, training=True):\n",
    "        source_input, target_input = inputs\n",
    "        # Create padding mask based on source tokens (assuming 0 is the padding token)\n",
    "        padding_mask = self.create_padding_mask(source_input)\n",
    "        enc_output = self.encoder(source_input, training=training, mask=padding_mask)\n",
    "        # Note: We rely on the decoder‚Äôs internal causal mask via use_causal_mask=True.\n",
    "        dec_output = self.decoder(target_input, enc_output, training=training, padding_mask=padding_mask)\n",
    "        final_output = self.final_layer(dec_output)\n",
    "        return final_output  # (batch_size, target_seq_len, target_vocab_size)\n",
    "\n",
    "    def create_padding_mask(self, seq):\n",
    "        mask = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "        return mask[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22abae50-73a3-4ec0-9c6b-3f56a9bcad17",
   "metadata": {},
   "source": [
    "* You're asking about a common way to create a padding mask in TensorFlow. Let's break down the create_padding_mask function step by step:\n",
    "\n",
    "* Python\n",
    "\n",
    "*def create_padding_mask(self, seq):\n",
    "*     mask = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "*     return mask[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
    "* 1. tf.math.equal(seq, 0):\n",
    "\n",
    "* This part checks for equality between each element in the input sequence seq and the value 0. Remember, 0 is conventionally used as the padding token.\n",
    "* The result is a boolean tensor. True indicates a padding token (where the value is 0), and False indicates a real token.\n",
    "* 2. tf.cast(..., tf.float32):\n",
    "\n",
    "* The boolean tensor is then cast to a float32 tensor. True becomes 1.0, and False becomes 0.0. This is important because the attention mechanism usually works with floating-point numbers.\n",
    "* 3. mask[:, tf.newaxis, tf.newaxis, :]:\n",
    "\n",
    "* This is the crucial part that reshapes the mask. Let's say the original mask has a shape of (batch_size, seq_len). This line adds two new dimensions:\n",
    "* tf.newaxis effectively inserts a new dimension of size 1.\n",
    "* The resulting shape becomes (batch_size, 1, 1, seq_len).\n",
    "* Why this reshaping?\n",
    "\n",
    "* The reason for this specific reshaping is often related to how attention mechanisms are implemented, especially in Transformer models.  The attention mechanism often involves broadcasting the mask during calculations.  The (1, 1) in the middle dimensions are there to facilitate this broadcasting.\n",
    "\n",
    "* Batch Size: The first dimension (batch_size) represents the number of sequences in the batch.\n",
    "* Sequence Length: The last dimension (seq_len) represents the length of each sequence.\n",
    "* The (1, 1) dimensions: These dimensions are added so that the mask can be easily broadcasted during the attention calculations, which often involve operations on tensors with shapes like (batch_size, num_heads, seq_len, seq_len) or similar. The (1,1) allows the mask to be applied correctly across different attention heads and positions within the sequences.\n",
    "* How it's Used:\n",
    "\n",
    "* The returned mask is then used in the attention mechanism.  Typically, the mask is applied to the attention weights before the softmax.  A large negative value (like -1e9) is added to the attention weights where the mask is 1 (padding tokens).  This forces the softmax to assign near-zero probability to the padding tokens, effectively excluding them from the attention calculation.\n",
    "\n",
    "* In Summary:\n",
    "\n",
    "* The create_padding_mask function takes a sequence of token IDs, identifies the padding tokens (usually represented by 0), and creates a mask that can be used to ignore these padding tokens during attention calculations.  The reshaping to (batch_size, 1, 1, seq_len) is a standard practice to make the mask compatible with the broadcasting operations commonly used in attention mechanisms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23e571f-22a1-4716-9682-c628ea6d4928",
   "metadata": {},
   "source": [
    "# Model Compilation & Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f990e36-2774-4f2d-a3d0-c37097a75ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "num_layers = 6\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "dff = 2048\n",
    "input_vocab_size = 10000\n",
    "target_vocab_size = 10000\n",
    "max_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a712db9-7fb9-416c-968a-f7f44f9e73e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Transformer model\n",
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                          input_vocab_size, target_vocab_size, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1454ee84-39cf-45e0-a579-88c0b1cfbe32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function (SparseCategoricalCrossentropy)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee9d3902-0116-4aed-a223-12392f74439d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer with an exponential decay learning rate schedule\n",
    "learning_rate = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.0001,\n",
    "    decay_steps=4000,\n",
    "    decay_rate=0.9\n",
    ")\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d93a6014-ce1a-4ce2-9357-ee43b04628b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "transformer.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3342dd-8515-448a-8521-34286f0295a4",
   "metadata": {},
   "source": [
    "# Dummy Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c19fed5-619e-4ce9-b9d6-763522923fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy data (replace with your real dataset)\n",
    "dummy_source = tf.random.uniform((64, 100), dtype=tf.int32, minval=0, maxval=200)\n",
    "dummy_target = tf.random.uniform((64, 100), dtype=tf.int32, minval=0, maxval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85d77f76-e4b3-43ac-9d79-b22945aadc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m210s\u001b[0m 29s/step - accuracy: 0.0041 - loss: 9.1026   \n",
      "Epoch 2/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 28s/step - accuracy: 0.0434 - loss: 8.5828\n",
      "Epoch 3/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 29s/step - accuracy: 0.2507 - loss: 8.1944\n",
      "Epoch 4/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 29s/step - accuracy: 0.5382 - loss: 7.8035\n",
      "Epoch 5/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 28s/step - accuracy: 0.8691 - loss: 7.3947\n",
      "Epoch 6/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 28s/step - accuracy: 0.9651 - loss: 6.9866\n",
      "Epoch 7/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 30s/step - accuracy: 0.9945 - loss: 6.6045\n",
      "Epoch 8/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 29s/step - accuracy: 0.9990 - loss: 6.2338\n",
      "Epoch 9/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 27s/step - accuracy: 0.9998 - loss: 5.8834\n",
      "Epoch 10/10\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 28s/step - accuracy: 1.0000 - loss: 5.5414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2267afa2db0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on dummy data\n",
    "transformer.fit(x=[dummy_source, dummy_target],\n",
    "                y=dummy_target,\n",
    "                batch_size=32,\n",
    "                epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2ea6eed8-08d2-4227-8326-e1a22c60b2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b604e9b1-0659-45c8-aa32-78fb9eafd135",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_bleu_score(model, dataset, source_vectorizer, target_vectorizer, num_samples=10):\n",
    "    \"\"\"\n",
    "    Evaluate Transformer model on a dataset using BLEU score.\n",
    "\n",
    "    Args:\n",
    "    - model: Trained Transformer model\n",
    "    - dataset: Preprocessed dataset (`tf.data.Dataset`)\n",
    "    - source_vectorizer: Vectorizer for English (source)\n",
    "    - target_vectorizer: Vectorizer for Telugu (target)\n",
    "    - num_samples: Number of sentences to evaluate\n",
    "    \n",
    "    Returns:\n",
    "    - Average BLEU score\n",
    "    \"\"\"\n",
    "    total_bleu = 0\n",
    "    smooth_fn = SmoothingFunction().method1  # Smoothing for better BLEU scores\n",
    "\n",
    "    for i, (source, target) in enumerate(dataset.take(num_samples)):  \n",
    "        # Convert tokenized input to string\n",
    "        source_text = \" \".join(source_vectorizer.get_vocabulary()[t] for t in source.numpy()[0] if t != 0)\n",
    "        target_text = \" \".join(target_vectorizer.get_vocabulary()[t] for t in target.numpy()[0] if t != 0)\n",
    "\n",
    "        # Generate prediction\n",
    "        predicted_tokens = model.predict(tf.expand_dims(source, axis=0))  # (1, seq_len, vocab_size)\n",
    "        predicted_tokens = np.argmax(predicted_tokens, axis=-1)  # Convert logits to token indices\n",
    "\n",
    "        # Convert predicted tokens back to text\n",
    "        predicted_text = \" \".join(target_vectorizer.get_vocabulary()[t] for t in predicted_tokens[0] if t != 0)\n",
    "\n",
    "        # Compute BLEU score\n",
    "        reference = [target_text.split()]  # BLEU expects list of reference lists\n",
    "        candidate = predicted_text.split()\n",
    "        bleu_score = sentence_bleu(reference, candidate, smoothing_function=smooth_fn)\n",
    "\n",
    "        print(f\"\\nExample {i+1}:\")\n",
    "        print(f\"Source: {source_text}\")\n",
    "        print(f\"Target: {target_text}\")\n",
    "        print(f\"Predicted: {predicted_text}\")\n",
    "        print(f\"BLEU Score: {bleu_score:.4f}\")\n",
    "\n",
    "        total_bleu += bleu_score\n",
    "\n",
    "    avg_bleu = total_bleu / num_samples\n",
    "    print(f\"\\nAverage BLEU Score: {avg_bleu:.4f}\")\n",
    "    return avg_bleu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5dd33f27-c049-4c77-8065-d751067c2e74",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m average_bleu \u001b[38;5;241m=\u001b[39m calculate_bleu_score(transformer, dataset\u001b[38;5;241m=\u001b[39mtest_dataset, \n\u001b[0;32m      2\u001b[0m                                     source_vectorizer\u001b[38;5;241m=\u001b[39msource_vectorizer, \n\u001b[0;32m      3\u001b[0m                                     target_vectorizer\u001b[38;5;241m=\u001b[39mtarget_vectorizer)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "average_bleu = calculate_bleu_score(transformer, dataset=test_dataset, \n",
    "                                    source_vectorizer=source_vectorizer, \n",
    "                                    target_vectorizer=target_vectorizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2681b576-fea0-4305-960d-d9b6d7088b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dushy\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\ops\\nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (1, 8, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: Hello, how are you?\n",
      "Translation: [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK] [UNK]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "def translate_sentence(model, sentence, source_vectorizer, target_vectorizer, max_len=100):\n",
    "    \"\"\"\n",
    "    Translates a single source sentence into the target language using the trained Transformer model.\n",
    "    \n",
    "    Args:\n",
    "        model: The trained Transformer model.\n",
    "        sentence: A raw source sentence (string).\n",
    "        source_vectorizer: A TextVectorization layer fitted on source language texts.\n",
    "        target_vectorizer: A TextVectorization layer fitted on target language texts.\n",
    "        max_len: Maximum length of the generated sequence.\n",
    "        \n",
    "    Returns:\n",
    "        predicted_sentence: The translated sentence as a string.\n",
    "    \"\"\"\n",
    "    # --- 1. Preprocess the source sentence ---\n",
    "    # The vectorizer converts the sentence to token indices (batch shape: (1, sequence_length))\n",
    "    source_tokens = source_vectorizer([sentence])\n",
    "    \n",
    "    # --- 2. Prepare the initial target sequence ---\n",
    "    # Here we assume your target vocabulary contains special tokens '<start>' and '<end>'.\n",
    "    # If you haven't added them, you can designate indices (e.g., 1 for start, 2 for end)\n",
    "    vocab = target_vectorizer.get_vocabulary()\n",
    "    try:\n",
    "        start_token = vocab.index('<start>')\n",
    "    except ValueError:\n",
    "        # Fallback if not present; adjust as needed.\n",
    "        start_token = 1  \n",
    "    try:\n",
    "        end_token = vocab.index('<end>')\n",
    "    except ValueError:\n",
    "        # Fallback if not present; adjust as needed.\n",
    "        end_token = 2  \n",
    "    \n",
    "    # Initialize the target sequence with the start token\n",
    "    output_tokens = [start_token]\n",
    "    \n",
    "    # --- 3. Iteratively generate the output tokens ---\n",
    "    for i in range(max_len):\n",
    "        # Prepare target input (shape: (1, current_sequence_length))\n",
    "        target_input = tf.expand_dims(output_tokens, axis=0)\n",
    "        \n",
    "        # Get predictions from the model (shape: (1, target_seq_len, target_vocab_size))\n",
    "        predictions = model([source_tokens, target_input], training=False)\n",
    "        \n",
    "        # Select the last token's logits and take argmax to get the next token id\n",
    "        next_token_logits = predictions[0, -1, :]\n",
    "        predicted_id = tf.argmax(next_token_logits).numpy()\n",
    "        \n",
    "        # Append the predicted token to the sequence\n",
    "        output_tokens.append(int(predicted_id))\n",
    "        \n",
    "        # If the end token is generated, stop the generation loop\n",
    "        if predicted_id == end_token:\n",
    "            break\n",
    "\n",
    "    # --- 4. Convert token indices back to words ---\n",
    "    # Remove the start token before converting (optional, based on your needs)\n",
    "    predicted_tokens = output_tokens[1:]\n",
    "    \n",
    "    # Convert tokens to words using the target vocabulary.\n",
    "    predicted_words = [vocab[token] for token in predicted_tokens if token < len(vocab)]\n",
    "    \n",
    "    # Optionally, remove tokens that appear after the end token (if any remain)\n",
    "    if '<end>' in predicted_words:\n",
    "        end_index = predicted_words.index('<end>')\n",
    "        predicted_words = predicted_words[:end_index]\n",
    "    \n",
    "    predicted_sentence = \" \".join(predicted_words)\n",
    "    return predicted_sentence\n",
    "\n",
    "# --- Example usage ---\n",
    "source_sentence = \"Hello, how are you?\"\n",
    "translated_sentence = translate_sentence(transformer, source_sentence, source_vectorizer, target_vectorizer)\n",
    "print(\"Source:\", source_sentence)\n",
    "print(\"Translation:\", translated_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2aee23-fb36-4009-a449-0ac0319affab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859b1d86-c0d4-43b6-864e-7c1dc441e5db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f311b2a6-c709-48a6-abe5-ea96a57a0d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0456e034-40d6-4c6c-83ae-fabed10ce530",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421949cf-99a6-49e1-b5e9-55663bc7353b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c6a67b-db2c-4cef-8173-e3ad6aeeb03f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2995e121-c2f6-4900-acc4-c47a5043a0e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850df4f7-82bb-4cd1-bcf1-2163cb59f020",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
